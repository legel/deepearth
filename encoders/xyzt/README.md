# Earth4D: Multi-Resolution 4D Spacetime Encoder for DeepEarth

Earth4D is a pioneering 4D spatiotemporal encoder that enables planetary-scale deep learning on Earth observation data. Built on NVIDIA's multi-resolution hash encoding architecture and extended to 4D spacetime, Earth4D efficiently encodes latitude, longitude, elevation, and time into learnable features at multiple scales - from sub-meter spatial resolution to microsecond temporal precision.

## üåç Core Innovation

Earth4D is the foundation of DeepEarth's ability to process and learn from the entire planet's observational data across space and time. By using decomposed hash encoding with separate spatial (xyz) and temporal (xyt, yzt, xzt) projections, it achieves:

- **Planetary Coverage**: Encode the entire Earth at 9.5cm resolution (default configuration)
- **Temporal Dynamics**: Capture 200 years of Earth history at hourly resolution (1900-2100)
- **Memory Efficiency**: Only 3.8GB GPU memory for training at sub-meter planetary scale
- **GPU Acceleration**: Custom CUDA kernels for real-time encoding at scale

## üöÄ Quick Start

### Installation

```bash
# Clone DeepEarth repository
git clone https://github.com/deepearth/deepearth.git
cd deepearth/encoders/xyzt

# Install dependencies
pip install torch numpy

# Build CUDA extension (requires NVIDIA GPU)
cd hashencoder
python setup.py build_ext --inplace
cd ..
```

### Basic Usage

```python
from earth4d import Earth4D
import torch

# Create encoder with default settings
# 0.095m spatial, ~1hr temporal over 200 years (1900-2100)
encoder = Earth4D()

# Input: [batch_size, 4] with [latitude, longitude, elevation_m, time_normalized]
# time_normalized: 0.0 = year 1900, 1.0 = year 2100
coordinates = torch.tensor([
    [40.7128, -74.0060, 100, 0.5],  # New York, year 2000
    [51.5074, -0.1278, 50, 0.75],   # London, year 2050
], device='cuda')

# Get encoded features
features = encoder(coordinates)
print(f"Features shape: {features.shape}")  # [2, 198]
```

### Testing

```bash
# Quick test with default configuration
python earth4d_test.py --mode quick

# Full test suite
python earth4d_test.py --mode full

# Memory profiling
python earth4d_test.py --mode memory

# Planetary scale test (sub-meter, hourly, 200 years)
python earth4d_test.py --mode planetary

# Custom configuration test
python earth4d_test.py --spatial-levels 20 --temporal-levels 16 --iterations 100
```

## üìä Configuration Guide

### Memory vs Resolution Tradeoffs

Earth4D's configuration determines the tradeoff between memory usage, resolution, and hash collisions. Here's a comprehensive guide:

#### Spatial Hash Table Sizes

| Log2 Size | Entries | Memory* | Collision-Free Resolution | Use Case |
|-----------|---------|---------|---------------------------|----------|
| 19 | 512K | 100 MB | ~10 km | Continental modeling |
| 20 | 1M | 200 MB | ~5 km | Regional weather |
| 22 | 4M | 1 GB | ~1 km | City-scale modeling |
| 24 | 16M | 4 GB | ~100 m | Urban planning |
| 26 | 64M | 14 GB | ~10 m | Building-level |
| 28** | 256M | 56 GB | ~1 m | Infrastructure |
| 30** | 1B | 224 GB | ~10 cm | Precision agriculture |

*Memory shown for typical 20-30 level configuration
**Requires int64 offset modification (not included in default)

#### Temporal Hash Table Sizes

| Log2 Size | Entries | Memory* | Collision-Free Resolution | Use Case |
|-----------|---------|---------|---------------------------|----------|
| 16 | 64K | 25 MB | ~1 week | Climate modeling |
| 18 | 256K | 100 MB | ~1 day | Weather forecasting |
| 20 | 1M | 400 MB | ~6 hours | Diurnal cycles |
| 22 | 4M | 1.6 GB | ~1 hour | Hourly observations |
| 24 | 16M | 6.4 GB | ~10 min | High-frequency data |

#### Resolution by Level Count

| Spatial Levels | Finest Resolution (growth=2.0) | Temporal Levels | Finest Resolution* |
|----------------|--------------------------------|-----------------|--------------------|
| 16 | 1.2 km | 12 | 3.4 days |
| 20 | 76 m | 16 | 5.3 hours |
| **24 (default)** | **0.095 m** | **19 (default)** | **0.84 hours** |
| 28 | 0.006 m | 24 | 3.2 minutes |
| 32 | 0.37 mm | 28 | 12 seconds |
| 36 | 23 Œºm | 32 | 0.75 seconds |

*Temporal resolution assumes 200-year range (1900-2100)

### Pre-configured Scenarios

#### üåç Default: Planetary Scale (1900-2100)
```python
encoder = Earth4D()  # Optimized defaults
# Encodes entire Earth at sub-meter resolution
# Covers 200 years of history and future projections
# Perfect for climate modeling, Earth observation, urban planning
```

#### üåê Global Climate (Light)
```python
encoder = Earth4D(
    spatial_levels=16,
    temporal_levels=12,
    spatial_log2_hashmap_size=19,  # 512K
    temporal_log2_hashmap_size=16   # 64K
)
# Memory: ~150 MB, Resolution: 1km/1day
```

#### üèôÔ∏è Urban Monitoring (City Scale)
```python
encoder = Earth4D(
    spatial_levels=20,
    temporal_levels=16,
    spatial_log2_hashmap_size=20,  # 1M
    temporal_log2_hashmap_size=18   # 256K
)
# Memory: ~400 MB model, Resolution: 76m spatial, 5hr temporal
```

#### üåç Planetary Scale Earth Observation (Default)
```python
encoder = Earth4D()  # Uses defaults optimized for 200-year planetary coverage
# spatial_levels=24, temporal_levels=19
# spatial_log2_hashmap_size=22, temporal_log2_hashmap_size=18
# Memory: 755 MB model, ~3.8 GB during training
# Resolution: 0.095m spatial, 0.84hr temporal over 200 years (1900-2100)
# Growth factor: 2.0 for optimal memory scaling
```

#### üî¨ Precision Agriculture (1m over 1km¬≤ area)
```python
encoder = Earth4D(
    spatial_levels=20,  # Fewer levels for local area
    temporal_levels=24,  # High temporal for crop monitoring
    spatial_log2_hashmap_size=20,  # 1M entries
    temporal_log2_hashmap_size=20   # 1M entries
)
# Memory: ~600 MB, Resolution: 1m/10min over local area
```

#### ‚ö° High-Frequency Sensing (Microseconds over 2 hours)
```python
encoder = Earth4D(
    spatial_levels=12,  # Coarse spatial
    temporal_levels=40,  # Ultra-fine temporal
    spatial_log2_hashmap_size=18,  # 256K
    temporal_log2_hashmap_size=24   # 16M for microsecond precision
)
# Memory: ~6.5 GB, Resolution: 10km/1Œºs over 2-hour window
```

## üîß Advanced Configuration

### Understanding Hash Collisions

Hash collisions occur when the total number of grid cells exceeds the hash table size. This is **expected and acceptable** for Earth data because:

1. **Natural Sparsity**: Earth observations are inherently sparse
   - Oceans, deserts, ice sheets have minimal observations
   - Most fine-scale grid cells are empty
   - Collisions between empty cells don't affect model performance

2. **Learned Disambiguation**: The model learns to resolve collisions
   - MLP decoder disambiguates based on multi-scale context
   - Coarse levels (collision-free) provide global context
   - Fine levels (with collisions) add local detail

3. **Collision Ratios** (24 levels, 2^22 hashmap):
   - Level 10 (98km): No collisions (direct indexing)
   - Level 15 (4.9km): ~1:1 (within hash table capacity)
   - Level 20 (76m): ~33:1 collisions (manageable)
   - Level 22 (19m): ~530:1 collisions (relies on sparsity)
   - Level 24 (0.095m): ~33,000:1 collisions (extreme sparsity required)

**Practical Impact**: The 3.61% MAPE achieved on AlphaEarth embeddings demonstrates successful collision handling at planetary scale.

### Comprehensive Configuration Table

| Parameter | Range | Impact | Memory Scaling | Collision Impact |
|-----------|-------|---------|---------------|------------------|
| `spatial_levels` | 8-40 | Resolution: 100km ‚Üí 0.1m | Linear: ~30MB/level | Exponential at fine scales |
| `temporal_levels` | 8-40 | Resolution: 1yr ‚Üí 1Œºs | Linear: ~5MB/level | Moderate |
| `spatial_log2_hashmap_size` | 16-26* | Hash table size | Exponential: 4^n | Inversely proportional |
| `temporal_log2_hashmap_size` | 14-24 | Hash table size | Exponential: 4^n | Inversely proportional |
| `features_per_level` | 1-8 | Feature dimensionality | Linear | None |
| `base_spatial_resolution` | 8-32 | Coarsest scale | None | Affects coarse levels |
| `growth_factor` | 1.5-2.0 | Scale progression | None | Affects distribution |

*Limited by int32 offsets in CUDA kernel

### Memory Formula

Total memory required during training:
```
Memory = 4 √ó Model Size
       = 4 √ó (Spatial_Params + Temporal_Params) √ó 4 bytes

Spatial_Params = min(2^spatial_hashmap, spatial_levels √ó grid_resolution¬≥) √ó features_per_level √ó spatial_levels
Temporal_Params = 3 √ó min(2^temporal_hashmap, temporal_levels √ó grid_resolution¬≥) √ó features_per_level √ó temporal_levels
```

## üèóÔ∏è Architecture Details

### Decomposed 4D Encoding

Earth4D uses a decomposed architecture optimized for spacetime:

1. **Spatial Encoder (XYZ)**: 3D hash encoding of ECEF coordinates
   - Encodes full 3D position in Earth-Centered Earth-Fixed frame
   - 24 levels √ó 2 features = 48D output
   - Hash table: 2^22 entries (4M)

2. **Spatiotemporal Projections**: Three 3D encodings capturing orthogonal planes:
   - **XYT**: Equatorial plane + time (X-Y plane through Earth's center)
   - **YZT**: 90¬∞E meridian plane + time (Y-Z plane through poles)
   - **XZT**: Prime meridian plane + time (X-Z plane through 0¬∞ longitude)
   - Each: 19 levels √ó 2 features = 38D output
   - Hash table: 2^18 entries (256K) per projection

Note: ECEF axes are NOT aligned with lat/lon/elevation:
- X: Points through 0¬∞ lat, 0¬∞ lon (equator/prime meridian intersection)
- Y: Points through 0¬∞ lat, 90¬∞E lon (equator in Indian Ocean)
- Z: Points through North Pole

### Coordinate System

- **Input**: WGS84 geodetic coordinates (latitude, longitude, elevation, time)
- **Internal**: ECEF (Earth-Centered Earth-Fixed) for uniform spatial hashing
- **Normalization**: Automatic scaling to [-1, 1] for hash encoding

### Hash Encoding Algorithm

#### Multi-Resolution Decomposition
For each level L (0 to 23 for spatial, 0 to 18 for temporal):
- Resolution at level L = `base_resolution * (2^L)`
- Creates progressively finer grids from 16 cells to 134M cells (spatial level 23)

#### Grid Mapping & Hashing
```cuda
// For each coordinate at each level:
1. Map to grid: pos_grid[d] = floor(input[d] * scale[d])
2. Calculate grid index:
   if (grid_size <= hashmap_size) {
      // Direct indexing for coarse levels (no collisions)
      index = x + y*stride_x + z*stride_xy
   } else {
      // Hash function for fine levels (with collisions)
      index = fast_hash(pos_grid) % hashmap_size
   }
```

#### XOR-Prime Hash Function
```cuda
uint32_t fast_hash(pos_grid[D]) {
    // Large primes for mixing (first is 1 for memory coherence)
    primes[] = {1, 2654435761, 805459861, 3674653429, ...}
    result = 0
    for d in D:
        result ^= pos_grid[d] * primes[d]
    return result
}
```

#### Smoothstep Interpolation
- Uses smoothstep function: `S(t) = 3t¬≤ - 2t¬≥`
- Provides C¬π continuous gradients (derivative: `6t(1-t)`)
- Trilinear interpolation across 8 corners (2¬≥ for 3D)
- Better than linear for continuous Earth phenomena

#### Feature Concatenation
- XYZ encoder ‚Üí 48D features (24 levels √ó 2 features)
- XYT encoder ‚Üí 38D features (19 levels √ó 2 features)
- YZT encoder ‚Üí 38D features (19 levels √ó 2 features)
- XZT encoder ‚Üí 38D features (19 levels √ó 2 features)
- **Total**: 162D feature vector

### Hash Table Properties

- **No Explicit Regularization**: No sparsity enforcement or uniform distribution constraints
- **Initialization**: Embeddings uniformly in [-0.1, 0.1] for strong gradient flow
- **Collision Handling**: Learned disambiguation through MLP decoder
- **Memory Efficiency**: 4M spatial + 3√ó256K temporal hash entries << theoretical grid size

## üìà Performance

### Benchmarks on NVIDIA L4 (24GB)

| Configuration | Parameters | Model Memory | Training Memory | Spatial Res | Temporal Res* |
|---------------|------------|-------------|----------------|-------------|---------------|
| Light (16/12) | ~50M | ~200 MB | ~800 MB | 1.2 km | 3.4 days |
| Urban (20/16) | ~100M | ~400 MB | ~1.6 GB | 76 m | 5.3 hours |
| **Planetary (24/19)** | **198M** | **755 MB** | **3.8 GB** | **0.095 m** | **0.84 hours** |
| Research-Max (28/24) | ~400M | ~1.5 GB | ~6 GB | 0.006 m | 3.2 minutes |

*Temporal resolution over 200-year range (1900-2100)

### Research Results

**Note: Earth4D is in active research and development.**

Testing planetary-scale configuration (24 spatial, 19 temporal levels):
- **Model Memory**: 755 MB (198M parameters)
- **Training Memory**: 3.8 GB (including gradients and optimizer)
- **Spatial Resolution**: 0.095m (9.5cm) globally
- **Temporal Resolution**: 0.84 hours over 200 years (1900-2100)
- **Growth Factor**: 2.0 (optimized from 1.5 for better memory scaling)
- **Discrimination**: Successfully distinguishes locations down to 1m apart
- **Hash Collisions**: Managed through Earth data sparsity

## üî¨ Research Applications

Earth4D enables breakthrough research in:

- **Climate Modeling**: Multi-scale climate dynamics from global to local
- **Weather Prediction**: High-resolution nowcasting with temporal continuity
- **Earth Observation**: Fusion of satellite, aerial, and ground sensors
- **Urban Planning**: Building-level environmental modeling
- **Agriculture**: Precision crop monitoring at plant scale
- **Disaster Response**: Real-time multi-scale hazard assessment

## üìö Technical Papers

Earth4D builds on:
- [Instant Neural Graphics Primitives](https://nvlabs.github.io/instant-ngp/) (M√ºller et al., 2022)
- [Grid4D](https://github.com/JiaweiXu8/Grid4D) (4D extension)

## ü§ù Contributing

Earth4D is a core component of DeepEarth. We welcome contributions for:
- Extended precision (int64 offsets for larger hash tables)
- Adaptive hash table sizing
- Hierarchical encoding strategies
- Application-specific optimizations

## üìÑ License

MIT License - See LICENSE file

## üôè Acknowledgments

Earth4D represents a breakthrough in planetary-scale deep learning, made possible by:
- NVIDIA's instant-ngp architecture
- The Grid4D spatiotemporal extension
- The DeepEarth vision of unified Earth intelligence

---

*Earth4D: Encoding the entire planet across space and time, one hash at a time.*