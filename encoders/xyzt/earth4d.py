"""
Earth4D: Grid4D Encoder for Planetary (X,Y,Z,T) Deep Learning
============================================================

Earth4D provides a Grid4D-based spatiotemporal encoder for planetary-scale 
deep learning tasks involving latitude, longitude, elevation, and time coordinates.

The encoder uses decomposed hash encoding with separate spatial (xyz) and 
temporal (xyt, yzt, xzt) projections for efficient 4D representation learning.

Key Features:
- Multi-resolution hash encoding for scalable feature extraction
- Configurable spatial and temporal resolution hierarchies
- Optional automatic ECEF coordinate conversion and normalization
- Configurable multi-resolution scales in meters and seconds
- Designed for planetary-scale spatiotemporal modeling

Usage:
    from deepearth.encoders.xyzt import Earth4D
    
    # Basic usage with normalized coordinates
    encoder = Earth4D()
    spatial_features, temporal_features = encoder(coordinates_xyzt)
    
    # Advanced usage with raw coordinates and custom scales
    encoder = Earth4D(
        auto_ecef_convert=True,
        spatial_scales_meters=[16, 32, 64, 128, 256, 512],
        temporal_scales_seconds=[3600, 86400, 604800]  # hour, day, week
    )
    features = encoder(raw_coordinates)

Author: Grid4D LFMC Team
License: MIT
"""

import torch
import torch.nn as nn
import numpy as np
from typing import List, Optional, Union, Tuple, Dict
import warnings

# Import hash encoder - adjust path as needed for your environment
try:
    from .hashencoder.hashgrid import HashEncoder
except ImportError:
    try:
        # Try absolute import if relative import fails
        from hashencoder.hashgrid import HashEncoder
    except ImportError:
        try:
            # Try adding current directory to path for direct script execution
            import os
            import sys
            current_dir = os.path.dirname(os.path.abspath(__file__))
            if current_dir not in sys.path:
                sys.path.insert(0, current_dir)
            from hashencoder.hashgrid import HashEncoder
        except ImportError:
            warnings.warn(
                "HashEncoder not found. Please install the hash encoding library. "
                "This encoder is required for Grid4D functionality."
            )
            HashEncoder = None


class CoordinateConverter:
    """
    Coordinate conversion utilities for Earth4D.

    Handles conversion between geographic coordinates (lat, lon, elevation, time)
    and normalized ECEF coordinates suitable for Grid4D encoding.
    """

    # WGS84 ellipsoid parameters
    WGS84_A = 6378137.0  # Semi-major axis in meters
    WGS84_F = 1.0 / 298.257223563  # Flattening
    WGS84_B = WGS84_A * (1 - WGS84_F)  # Semi-minor axis
    WGS84_E2 = 2 * WGS84_F - WGS84_F * WGS84_F  # First eccentricity squared

    def __init__(self,
                 use_wgs84: bool = True,
                 earth_radius: float = 6371000.0,  # meters (fallback if not WGS84)
                 time_origin: float = 0.0,          # reference time
                 time_scale: float = 1.0):          # time scaling factor
        """
        Initialize coordinate converter.

        Args:
            use_wgs84: Use WGS84 ellipsoid (True) or spherical approximation (False)
            earth_radius: Earth radius in meters for spherical approximation
            time_origin: Reference time point (seconds since epoch)
            time_scale: Scaling factor for time normalization
        """
        self.use_wgs84 = use_wgs84
        self.earth_radius = earth_radius
        self.time_origin = time_origin
        self.time_scale = time_scale
        
    def geographic_to_ecef(self,
                          lat: torch.Tensor,
                          lon: torch.Tensor,
                          elevation: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        Convert geographic coordinates (lat, lon, elevation) to ECEF.

        Args:
            lat: Latitude in degrees
            lon: Longitude in degrees
            elevation: Elevation in meters above sea level

        Returns:
            Tuple of (x, y, z) ECEF coordinates in meters
        """
        # Convert to radians
        lat_rad = torch.deg2rad(lat)
        lon_rad = torch.deg2rad(lon)

        if self.use_wgs84:
            # WGS84 ellipsoid conversion
            sin_lat = torch.sin(lat_rad)
            cos_lat = torch.cos(lat_rad)
            sin_lon = torch.sin(lon_rad)
            cos_lon = torch.cos(lon_rad)

            # Prime vertical radius of curvature
            N = self.WGS84_A / torch.sqrt(1 - self.WGS84_E2 * sin_lat * sin_lat)

            # ECEF coordinates
            x = (N + elevation) * cos_lat * cos_lon
            y = (N + elevation) * cos_lat * sin_lon
            z = (N * (1 - self.WGS84_E2) + elevation) * sin_lat
        else:
            # Spherical approximation (original implementation)
            radius = self.earth_radius + elevation
            x = radius * torch.cos(lat_rad) * torch.cos(lon_rad)
            y = radius * torch.cos(lat_rad) * torch.sin(lon_rad)
            z = radius * torch.sin(lat_rad)

        return x, y, z
    
    def normalize_coordinates(self,
                            x: torch.Tensor,
                            y: torch.Tensor,
                            z: torch.Tensor,
                            t: torch.Tensor,
                            spatial_bound: float = 1.0,
                            temporal_bound: float = 1.0) -> torch.Tensor:
        """
        Normalize ECEF coordinates and time to [0, 1] range.

        Args:
            x, y, z: ECEF coordinates
            t: Time coordinates
            spatial_bound: Spatial normalization bound
            temporal_bound: Temporal normalization bound

        Returns:
            Normalized coordinates tensor of shape (..., 4)
        """
        # Use fixed normalization bounds based on Earth's size
        # This ensures consistent normalization across batches
        if self.use_wgs84:
            # Maximum ECEF coordinates are roughly Earth radius + max elevation
            max_coord = self.WGS84_A + 10000  # Allow for up to 10km elevation
        else:
            max_coord = self.earth_radius + 10000

        # Normalize spatial coordinates to [-spatial_bound, spatial_bound]
        # HashEncoder expects coordinates in [-size, size] range
        x_norm = (x / max_coord) * spatial_bound
        y_norm = (y / max_coord) * spatial_bound
        z_norm = (z / max_coord) * spatial_bound

        # Ensure coordinates are in valid range [-spatial_bound, spatial_bound]
        x_norm = torch.clamp(x_norm, -spatial_bound, spatial_bound)
        y_norm = torch.clamp(y_norm, -spatial_bound, spatial_bound)
        z_norm = torch.clamp(z_norm, -spatial_bound, spatial_bound)

        # Normalize temporal coordinates
        # Assume t is already in [0, 1] range or handle it appropriately
        if t.min() < 0 or t.max() > 1:
            # If time is not normalized, normalize to [0, 1]
            t_min = t.min()
            t_max = t.max()
            t_range = t_max - t_min + 1e-6  # Avoid division by zero
            t_norm = (t - t_min) / t_range * temporal_bound
        else:
            t_norm = t * temporal_bound

        return torch.stack([x_norm, y_norm, z_norm, t_norm], dim=-1)
    
    def process_raw_coordinates(self,
                               lat: torch.Tensor,
                               lon: torch.Tensor, 
                               elevation: torch.Tensor,
                               time: torch.Tensor,
                               spatial_bound: float = 1.0,
                               temporal_bound: float = 1.0) -> torch.Tensor:
        """
        Complete pipeline: geographic -> ECEF -> normalized.
        
        Args:
            lat: Latitude in degrees
            lon: Longitude in degrees
            elevation: Elevation in meters
            time: Time coordinates
            spatial_bound: Spatial normalization bound
            temporal_bound: Temporal normalization bound
            
        Returns:
            Normalized XYZT coordinates tensor
        """
        # Convert to ECEF
        x, y, z = self.geographic_to_ecef(lat, lon, elevation)
        
        # Normalize
        return self.normalize_coordinates(x, y, z, time, spatial_bound, temporal_bound)


class Grid4DSpatiotemporalEncoder(nn.Module):
    """
    Core Grid4D spatiotemporal encoder.

    Implements decomposed hash encoding for 4D coordinates with separate
    spatial (xyz) and temporal (xyt, yzt, xzt) encoding pathways.
    """

    def __init__(self,
                 # Spatial encoding configuration
                 spatial_levels: int = 24,  # Match Earth4D default
                 spatial_features: int = 2,
                 spatial_base_res: int = 16,
                 spatial_max_res: int = 134217728,  # 2^27 for sub-meter
                 spatial_hashmap: int = 22,  # Match Earth4D default
                 # Temporal encoding configuration
                 temporal_levels: int = 19,  # Match Earth4D default
                 temporal_features: int = 2,
                 temporal_base_res: List[int] = None,
                 temporal_max_res: List[int] = None,
                 temporal_hashmap: int = 18,  # Match Earth4D default
                 # Coordinate bounds
                 spatial_bound: float = 1.0,
                 temporal_bound: float = 1.0,
                 # Reporting
                 verbose: bool = True):
        """
        Initialize Grid4D encoder.

        Args:
            spatial_*: Configuration for xyz spatial encoding
            temporal_*: Configuration for 3D temporal projection encodings
            spatial_bound: Normalization bound for spatial coordinates
            temporal_bound: Normalization bound for temporal coordinates
            verbose: Print resolution scale table on initialization
        """
        super().__init__()
        
        if HashEncoder is None:
            raise ImportError(
                "HashEncoder is required for Grid4D functionality. "
                "Please install the hash encoding library."
            )
        
        # Default temporal resolutions if not provided
        if temporal_base_res is None:
            temporal_base_res = [8, 8, 8]
        if temporal_max_res is None:
            temporal_max_res = [32, 32, 16]
            
        self.spatial_bound = spatial_bound
        self.temporal_bound = temporal_bound

        # Store hashmap sizes for reporting
        self.spatial_log2_hashmap_size = spatial_hashmap
        self.temporal_log2_hashmap_size = temporal_hashmap

        # Store dimensions for output
        self.spatial_dim = spatial_levels * spatial_features
        self.temporal_dim = temporal_levels * temporal_features * 3  # 3 projections
        self.output_dim = self.spatial_dim + self.temporal_dim
        
        # Spatial encoder for xyz coordinates
        self.xyz_encoder = HashEncoder(
            input_dim=3,
            num_levels=spatial_levels,
            level_dim=spatial_features,
            per_level_scale=2,
            base_resolution=spatial_base_res,
            log2_hashmap_size=spatial_hashmap,
            desired_resolution=spatial_max_res
        )
        
        # Temporal projection encoders (xyt, yzt, xzt)
        self.xyt_encoder = HashEncoder(
            input_dim=3,
            num_levels=temporal_levels,
            level_dim=temporal_features,
            per_level_scale=2,
            base_resolution=temporal_base_res,
            log2_hashmap_size=temporal_hashmap,
            desired_resolution=temporal_max_res
        )
        
        self.yzt_encoder = HashEncoder(
            input_dim=3,
            num_levels=temporal_levels,
            level_dim=temporal_features,
            per_level_scale=2,
            base_resolution=temporal_base_res,
            log2_hashmap_size=temporal_hashmap,
            desired_resolution=temporal_max_res
        )
        
        self.xzt_encoder = HashEncoder(
            input_dim=3,
            num_levels=temporal_levels,
            level_dim=temporal_features,
            per_level_scale=2,
            base_resolution=temporal_base_res,
            log2_hashmap_size=temporal_hashmap,
            desired_resolution=temporal_max_res
        )

        # Calculate and display resolution scales
        if verbose:
            self._print_resolution_table()

    def _calculate_resolution_scales(self) -> Dict:
        """Calculate resolution scales for all encoders and levels."""
        import numpy as np

        # For normalized ECEF coordinates in [-1, 1] range
        # Physical range is approximately 2 * Earth radius
        earth_radius = 6371000.0  # meters
        physical_range = 2 * earth_radius  # pole-to-pole distance

        results = {'spatial': [], 'temporal': {'xyt': [], 'yzt': [], 'xzt': []}}

        # Calculate spatial resolutions
        spatial_encoder = self.xyz_encoder
        for level in range(spatial_encoder.num_levels):
            base_res = spatial_encoder.base_resolution[0].item()
            scale = spatial_encoder.per_level_scale[0].item()
            grid_resolution = np.ceil(base_res * (scale ** level))
            meters_per_cell = physical_range / grid_resolution

            results['spatial'].append({
                'level': level,
                'grid_resolution': int(grid_resolution),
                'meters_per_cell': meters_per_cell,
                'km_per_cell': meters_per_cell / 1000
            })

        # Calculate temporal resolutions (simplified for now)
        for name, encoder in [('xyt', self.xyt_encoder), ('yzt', self.yzt_encoder), ('xzt', self.xzt_encoder)]:
            for level in range(encoder.num_levels):
                base_res = encoder.base_resolution[0].item()
                scale = encoder.per_level_scale[0].item()
                grid_resolution = np.ceil(base_res * (scale ** level))

                # For temporal, we interpret this as time resolution
                # Assuming normalized time range of 1 year for display
                seconds_per_year = 365.25 * 24 * 3600
                seconds_per_cell = seconds_per_year / grid_resolution

                results['temporal'][name].append({
                    'level': level,
                    'grid_resolution': int(grid_resolution),
                    'seconds_per_cell': seconds_per_cell,
                    'days_per_cell': seconds_per_cell / 86400
                })

        return results

    def _print_resolution_table(self):
        """Print detailed resolution table for all encoders."""
        results = self._calculate_resolution_scales()

        print("\n" + "="*80)
        print("EARTH4D RESOLUTION SCALE TABLE")
        print("="*80)

        # Print spatial resolutions
        print("\nSPATIAL ENCODER (XYZ):")
        print(f"{'Level':<6} {'Grid Res':<12} {'Meters/Cell':<15} {'KM/Cell':<12}")
        print("-" * 50)
        for item in results['spatial']:
            # Use appropriate precision based on scale
            if item['meters_per_cell'] >= 100:
                meters_str = f"{item['meters_per_cell']:.1f}"
            elif item['meters_per_cell'] >= 1:
                meters_str = f"{item['meters_per_cell']:.2f}"
            elif item['meters_per_cell'] >= 0.01:
                meters_str = f"{item['meters_per_cell']:.3f}"
            else:
                meters_str = f"{item['meters_per_cell']:.4f}"

            if item['km_per_cell'] >= 1:
                km_str = f"{item['km_per_cell']:.2f}"
            elif item['km_per_cell'] >= 0.001:
                km_str = f"{item['km_per_cell']:.3f}"
            else:
                km_str = f"{item['km_per_cell']:.4f}"

            print(f"{item['level']:<6} {item['grid_resolution']:<12} "
                  f"{meters_str:<15} {km_str:<12}")

        # Print temporal resolutions (just one example)
        print("\nTEMPORAL ENCODERS (XYT, YZT, XZT):")
        print(f"{'Level':<6} {'Grid Res':<12} {'Seconds/Cell':<15} {'Days/Cell':<12}")
        print("-" * 50)
        for item in results['temporal']['xyt']:  # Show all levels
            print(f"{item['level']:<6} {item['grid_resolution']:<12} "
                  f"{item['seconds_per_cell']:<15.1f} {item['days_per_cell']:<12.2f}")

        # Print memory summary
        total_params = (
            self.xyz_encoder.embeddings.numel() +
            self.xyt_encoder.embeddings.numel() +
            self.yzt_encoder.embeddings.numel() +
            self.xzt_encoder.embeddings.numel()
        )
        memory_mb = total_params * 4 / (1024 * 1024)  # float32

        # Calculate hash table information
        spatial_hash_size = 2 ** self.spatial_log2_hashmap_size
        temporal_hash_size = 2 ** self.temporal_log2_hashmap_size

        # Calculate actual vs theoretical parameters
        spatial_actual = self.xyz_encoder.embeddings.numel()
        temporal_actual = (self.xyt_encoder.embeddings.numel() +
                          self.yzt_encoder.embeddings.numel() +
                          self.xzt_encoder.embeddings.numel())

        print(f"\nHASH TABLE CONFIGURATION:")
        print(f"  Spatial hash table: 2^{self.spatial_log2_hashmap_size} = {spatial_hash_size:,} entries")
        print(f"  Temporal hash table: 2^{self.temporal_log2_hashmap_size} = {temporal_hash_size:,} entries")
        print(f"\nACTUAL PARAMETERS:")
        print(f"  Spatial encoder: {spatial_actual:,} params")
        print(f"  Temporal encoders: {temporal_actual:,} params")
        print(f"  Total: {total_params:,} params")
        print(f"\nMEMORY USAGE:")
        print(f"  Model size (float32): {memory_mb:.1f} MB")
        print(f"  Note: Hash collisions occur when grid cells > hash table size")
        print("="*80 + "\n")

    def encode_spatial(self, xyz: torch.Tensor, collision_tracking=None) -> torch.Tensor:
        """
        Encode spatial xyz coordinates.

        Args:
            xyz: Tensor of shape (..., 3) with normalized coordinates
            collision_tracking: Optional collision tracking data for xyz encoder

        Returns:
            Spatial features of shape (..., spatial_dim)
        """
        # Debug: Check coordinate ranges
        if False:  # Set to True for debugging
            print(f"encode_spatial - xyz range: [{xyz.min().item():.4f}, {xyz.max().item():.4f}]")
            # After normalization in HashEncoder forward
            normalized = (xyz + self.spatial_bound) / (2 * self.spatial_bound)
            print(f"  After normalization: [{normalized.min().item():.4f}, {normalized.max().item():.4f}]")

        return self.xyz_encoder(xyz, size=self.spatial_bound, collision_tracking=collision_tracking)
    
    def encode_temporal(self, xyzt: torch.Tensor, collision_tracking=None) -> torch.Tensor:
        """
        Encode temporal projections (xyt, yzt, xzt).
        
        Args:
            xyzt: Tensor of shape (..., 4) with normalized coordinates
            collision_tracking: Optional collision tracking data for temporal encoders
            
        Returns:
            Temporal features of shape (..., temporal_dim)
        """
        # Scale time dimension appropriately
        xyz_scaled = xyzt[..., :3]
        t_scaled = (xyzt[..., 3:] * 2 * self.temporal_bound - self.temporal_bound) * 0.9
        xyzt_scaled = torch.cat([xyz_scaled, t_scaled], dim=-1)
        
        # Create 3D projections with time
        xyt = torch.cat([xyzt_scaled[..., :2], xyzt_scaled[..., 3:]], dim=-1)
        yzt = xyzt_scaled[..., 1:]
        xzt = torch.cat([xyzt_scaled[..., :1], xyzt_scaled[..., 2:]], dim=-1)
        
        # Extract collision tracking for each encoder if provided
        xyt_tracking = collision_tracking.get('xyt') if collision_tracking else None
        yzt_tracking = collision_tracking.get('yzt') if collision_tracking else None
        xzt_tracking = collision_tracking.get('xzt') if collision_tracking else None
        
        # Encode each projection
        xyt_features = self.xyt_encoder(xyt, size=self.temporal_bound, collision_tracking=xyt_tracking)
        yzt_features = self.yzt_encoder(yzt, size=self.temporal_bound, collision_tracking=yzt_tracking)
        xzt_features = self.xzt_encoder(xzt, size=self.temporal_bound, collision_tracking=xzt_tracking)
        
        # Concatenate temporal features
        return torch.cat([xyt_features, yzt_features, xzt_features], dim=-1)
    
    def forward(self, xyzt: torch.Tensor, collision_tracking=None) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Encode 4D spatiotemporal coordinates.
        
        Args:
            xyzt: Tensor of shape (..., 4) with normalized coordinates
            collision_tracking: Optional collision tracking data
            
        Returns:
            Tuple of (spatial_features, temporal_features)
        """
        xyz = xyzt[..., :3]
        
        # Extract collision tracking for spatial and temporal encoders
        spatial_tracking = collision_tracking.get('xyz') if collision_tracking else None
        temporal_tracking = collision_tracking if collision_tracking else None
        
        spatial_features = self.encode_spatial(xyz, collision_tracking=spatial_tracking)
        temporal_features = self.encode_temporal(xyzt, collision_tracking=temporal_tracking)
        return spatial_features, temporal_features


class Earth4D(nn.Module):
    """
    Earth4D: Complete Grid4D encoder for planetary spatiotemporal modeling.

    Main interface for Earth4D functionality with optional coordinate conversion,
    configurable multi-resolution scales, and flexible input handling.
    """

    def __init__(self,
                 # Core encoder configuration - production-tested values
                 spatial_levels: int = 24,  # Production default: 24 levels for ~1km resolution  
                 temporal_levels: int = 19,  # Production default: 19 levels for 200-year coverage
                 features_per_level: int = 2,
                 spatial_log2_hashmap_size: int = 23,  # Production: 4M entries (1GB, tested on L4 GPU)
                 temporal_log2_hashmap_size: int = 18,  # Production: 256K entries
                 base_spatial_resolution: float = 16.0,
                 base_temporal_resolution: float = 8.0,
                 growth_factor: float = 2.0,  # Production: 2.0 for optimal memory/accuracy tradeoff
                 target_spatial_km: float = None,
                 target_temporal_days: float = None,
                 verbose: bool = True,
                 # Collision tracking configuration
                 enable_collision_tracking: bool = False,
                 max_tracked_examples: int = 10000):
        """
        Initialize Earth4D encoder.

        Args:
            spatial_levels: Number of spatial hash levels (default: 24, production-tested)
                - 24 levels: Achieves 3.61% MAPE on AlphaEarth prediction
                - Provides ~1km to sub-meter multi-resolution coverage
            temporal_levels: Number of temporal hash levels (default: 19, production-tested)
                - 19 levels: Covers 200 years (1900-2100) at ~1hr precision
            features_per_level: Features per level (default: 2)
            spatial_log2_hashmap_size: Log2 of spatial hashmap size (default: 22 = 4M entries)
                - 19: 512K entries (100MB, ~10km resolution, regional models)
                - 22: 4M entries (1GB, ~1km resolution, continental - RECOMMENDED)
                - 24: 16M entries (4GB, ~100m resolution, country-scale)
                - 26: 64M entries (14GB, ~10m resolution, city-scale)
            temporal_log2_hashmap_size: Log2 of temporal hashmap size (default: 18 = 256K entries)
            base_spatial_resolution: Base resolution for spatial encoder (default: 16)
            base_temporal_resolution: Base resolution for temporal encoder (default: 8)  
            growth_factor: Growth factor between levels (default: 2.0, optimal for memory)
            target_spatial_km: Optional target spatial resolution in kilometers for display
            target_temporal_days: Optional target temporal resolution in days for display
            verbose: Print resolution table on initialization (default: True)

        Production Performance (tested on 3.2M GBIF samples):
            - Training: 200 epochs in <2 hours on single L4 GPU (24GB)
            - Memory: ~17MB encoder, ~20MB total model
            - Accuracy: 3.61% MAPE on 64D AlphaEarth embeddings
        
        Note: Hash collisions are expected and acceptable for sparse Earth data.
        The encoder leverages natural sparsity of high-frequency spatial variations.
        """
        super().__init__()

        self.verbose = verbose
        self.target_spatial_km = target_spatial_km
        self.target_temporal_days = target_temporal_days

        # WGS84 ellipsoid parameters for coordinate conversion
        self.WGS84_A = 6378137.0  # Semi-major axis in meters
        self.WGS84_F = 1.0 / 298.257223563  # Flattening
        self.WGS84_E2 = 2 * self.WGS84_F - self.WGS84_F**2  # First eccentricity squared

        # Calculate max resolutions based on levels and growth factor
        spatial_max_res = int(base_spatial_resolution * (growth_factor ** (spatial_levels - 1)))

        # For temporal, use list for 3 projections with lower base resolution
        temporal_base_res = [int(base_temporal_resolution)] * 3
        temporal_max_res = [int(base_temporal_resolution * (growth_factor ** (temporal_levels - 1)))] * 3

        # Initialize the encoder
        self.encoder = Grid4DSpatiotemporalEncoder(
            spatial_levels=spatial_levels,
            spatial_features=features_per_level,
            spatial_base_res=int(base_spatial_resolution),
            spatial_max_res=spatial_max_res,
            spatial_hashmap=spatial_log2_hashmap_size,
            temporal_levels=temporal_levels,
            temporal_features=features_per_level,
            temporal_base_res=temporal_base_res,
            temporal_max_res=temporal_max_res,
            temporal_hashmap=temporal_log2_hashmap_size,
            spatial_bound=1.0,
            temporal_bound=1.0,
            verbose=False  # We'll print our own info
        )

        # Initialize collision tracking
        self.enable_collision_tracking = enable_collision_tracking
        self.max_tracked_examples = max_tracked_examples
        self.collision_tracking_data = None
        
        if self.enable_collision_tracking:
            self._init_collision_tracking()

        if self.verbose:
            self._print_resolution_info()
            if self.target_spatial_km is not None or self.target_temporal_days is not None:
                self._print_target_resolution()
    
    def _init_collision_tracking(self):
        """Initialize collision tracking tensors."""
        # Get spatial and temporal levels for all 4 grid spaces
        spatial_levels = self.encoder.xyz_encoder.num_levels
        temporal_levels = self.encoder.xyt_encoder.num_levels
        
        # Initialize collision tracking data structure
        self.collision_tracking_data = {
            'xyz': {
                'collision_indices': torch.zeros((self.max_tracked_examples, spatial_levels, 3), dtype=torch.int32, device='cuda'),
                'collision_flags': torch.zeros((self.max_tracked_examples, spatial_levels), dtype=torch.bool, device='cuda'),
                'max_tracked_examples': self.max_tracked_examples,
                'example_offset': 0
            },
            'xyt': {
                'collision_indices': torch.zeros((self.max_tracked_examples, temporal_levels, 3), dtype=torch.int32, device='cuda'),
                'collision_flags': torch.zeros((self.max_tracked_examples, temporal_levels), dtype=torch.bool, device='cuda'),
                'max_tracked_examples': self.max_tracked_examples,
                'example_offset': 0
            },
            'yzt': {
                'collision_indices': torch.zeros((self.max_tracked_examples, temporal_levels, 3), dtype=torch.int32, device='cuda'),
                'collision_flags': torch.zeros((self.max_tracked_examples, temporal_levels), dtype=torch.bool, device='cuda'),
                'max_tracked_examples': self.max_tracked_examples,
                'example_offset': 0
            },
            'xzt': {
                'collision_indices': torch.zeros((self.max_tracked_examples, temporal_levels, 3), dtype=torch.int32, device='cuda'),
                'collision_flags': torch.zeros((self.max_tracked_examples, temporal_levels), dtype=torch.bool, device='cuda'),
                'max_tracked_examples': self.max_tracked_examples,
                'example_offset': 0
            },
            # Coordinate tracking
            'coordinates': {
                'original': torch.zeros((self.max_tracked_examples, 4), dtype=torch.float32, device='cuda'),  # lat, lon, elev, time
                'normalized': torch.zeros((self.max_tracked_examples, 4), dtype=torch.float32, device='cuda'),  # x_norm, y_norm, z_norm, time
                'count': 0  # Number of examples tracked so far
            }
        }
        
    def _print_resolution_info(self):
        """Print detailed resolution information."""
        # Get resolution scales from encoder
        results = self.encoder._calculate_resolution_scales()

        print("\n" + "="*80)
        print("EARTH4D RESOLUTION SCALE TABLE")
        print("="*80)

        # Print spatial resolutions with improved precision
        print("\nSPATIAL ENCODER (XYZ):")
        print(f"{'Level':<6} {'Grid Res':<12} {'Meters/Cell':<15} {'KM/Cell':<12}")
        print("-" * 50)
        for item in results['spatial']:
            # Format with appropriate precision for sub-meter values
            if item['meters_per_cell'] >= 1000:
                meters_str = f"{item['meters_per_cell']/1000:.1f}km"
            elif item['meters_per_cell'] >= 100:
                meters_str = f"{item['meters_per_cell']:.1f}m"
            elif item['meters_per_cell'] >= 10:
                meters_str = f"{item['meters_per_cell']:.2f}m"
            elif item['meters_per_cell'] >= 1:
                meters_str = f"{item['meters_per_cell']:.3f}m"
            else:
                # Sub-meter: show in millimeters if very small
                if item['meters_per_cell'] < 0.01:
                    meters_str = f"{item['meters_per_cell']*1000:.2f}mm"
                else:
                    meters_str = f"{item['meters_per_cell']:.4f}m"

            if item['km_per_cell'] >= 1:
                km_str = f"{item['km_per_cell']:.2f}"
            elif item['km_per_cell'] >= 0.001:
                km_str = f"{item['km_per_cell']:.3f}"
            else:
                km_str = f"{item['km_per_cell']:.4f}"

            print(f"{item['level']:<6} {item['grid_resolution']:<12} "
                  f"{meters_str:<15} {km_str:<12}")

        # Print temporal resolutions
        print("\nTEMPORAL ENCODERS (XYT, YZT, XZT):")
        print(f"{'Level':<6} {'Grid Res':<12} {'Seconds/Cell':<15} {'Days/Cell':<12}")
        print("-" * 50)
        for item in results['temporal']['xyt']:
            print(f"{item['level']:<6} {item['grid_resolution']:<12} "
                  f"{item['seconds_per_cell']:<15.1f} {item['days_per_cell']:<12.2f}")

        # Calculate parameters
        spatial_params = self.encoder.xyz_encoder.embeddings.numel()
        temporal_params = (self.encoder.xyt_encoder.embeddings.numel() +
                          self.encoder.yzt_encoder.embeddings.numel() +
                          self.encoder.xzt_encoder.embeddings.numel())
        total_params = spatial_params + temporal_params

        # Memory calculations
        spatial_memory = spatial_params * 4 / (1024 * 1024)  # float32 to MB
        temporal_memory = temporal_params * 4 / (1024 * 1024)
        total_memory = spatial_memory + temporal_memory

        # Hash table configuration
        spatial_hash_entries = 2 ** self.encoder.spatial_log2_hashmap_size
        temporal_hash_entries = 2 ** self.encoder.temporal_log2_hashmap_size

        print(f"\nHASH TABLE CONFIGURATION:")
        print(f"  Spatial: 2^{self.encoder.spatial_log2_hashmap_size} = {spatial_hash_entries:,} entries")
        print(f"  Temporal: 2^{self.encoder.temporal_log2_hashmap_size} = {temporal_hash_entries:,} entries")
        print(f"  Total capacity: {spatial_hash_entries + temporal_hash_entries*3:,} entries")

        print(f"\nACTUAL PARAMETERS (MEMORY FOOTPRINT):")
        print(f"  Spatial encoders: {spatial_params:,} params = {spatial_memory:.2f} MB")
        print(f"  Temporal encoders: {temporal_params:,} params = {temporal_memory:.2f} MB")
        print(f"  Total: {total_params:,} params = {total_memory:.2f} MB")
        print(f"  During training (4x): ~{total_memory * 4:.2f} MB")

        # Explain the difference
        if total_params < spatial_hash_entries + temporal_hash_entries*3:
            utilization = (total_params / (spatial_hash_entries + temporal_hash_entries*3)) * 100
            print(f"\n  Note: Using {utilization:.1f}% of hash table capacity")
            print(f"  (Hash collisions allow encoding more locations than parameters)")

    def _print_target_resolution(self):
        """Print target resolution in user-friendly units."""
        print(f"\nTARGET RESOLUTION:")
        if self.target_spatial_km is not None:
            # Convert to appropriate units
            if self.target_spatial_km >= 1.0:
                print(f"  Spatial: {self.target_spatial_km:.1f} km")
            elif self.target_spatial_km >= 0.001:
                print(f"  Spatial: {self.target_spatial_km * 1000:.1f} meters")
            else:
                print(f"  Spatial: {self.target_spatial_km * 1000000:.1f} millimeters")

        if self.target_temporal_days is not None:
            # Convert to appropriate units
            if self.target_temporal_days >= 1.0:
                print(f"  Temporal: {self.target_temporal_days:.1f} days")
            elif self.target_temporal_days >= 1/24:
                print(f"  Temporal: {self.target_temporal_days * 24:.1f} hours")
            elif self.target_temporal_days >= 1/1440:
                print(f"  Temporal: {self.target_temporal_days * 1440:.1f} minutes")
            else:
                print(f"  Temporal: {self.target_temporal_days * 86400:.1f} seconds")
        print("="*80 + "\n")

    def forward(self, coords: torch.Tensor) -> torch.Tensor:
        """
        Forward pass through Earth4D encoder.

        Args:
            coords: Input coordinates tensor (..., 4)
                    Format: [latitude, longitude, elevation_m, time_normalized]
                    - Latitude: -90 to 90 degrees
                    - Longitude: -180 to 180 degrees
                    - Elevation: meters above sea level
                    - Time: normalized to [0, 1]

        Returns:
            Concatenated features tensor
        """
        # Convert lat/lon/elev to ECEF and normalize
        lat = coords[..., 0]
        lon = coords[..., 1]
        elev = coords[..., 2]
        time = coords[..., 3]

        # Convert to ECEF using WGS84
        lat_rad = torch.deg2rad(lat)
        lon_rad = torch.deg2rad(lon)

        sin_lat = torch.sin(lat_rad)
        cos_lat = torch.cos(lat_rad)
        sin_lon = torch.sin(lon_rad)
        cos_lon = torch.cos(lon_rad)

        # WGS84 parameters
        N = self.WGS84_A / torch.sqrt(1 - self.WGS84_E2 * sin_lat * sin_lat)

        x = (N + elev) * cos_lat * cos_lon
        y = (N + elev) * cos_lat * sin_lon
        z = (N * (1 - self.WGS84_E2) + elev) * sin_lat

        # Normalize ECEF to [-1, 1]
        # Earth radius is approximately 6371km, so max ECEF is ~6400km
        norm_factor = 6400000.0  # 6400km in meters
        x_norm = x / norm_factor
        y_norm = y / norm_factor
        z_norm = z / norm_factor

        # Stack normalized coordinates
        norm_coords = torch.stack([x_norm, y_norm, z_norm, time], dim=-1)

        # Save coordinates for collision tracking if enabled
        if self.enable_collision_tracking and self.collision_tracking_data['coordinates']['count'] < self.max_tracked_examples:
            current_count = self.collision_tracking_data['coordinates']['count']
            batch_size = coords.shape[0]
            remaining_slots = self.max_tracked_examples - current_count
            save_count = min(batch_size, remaining_slots)
            
            if save_count > 0:
                # Save original coordinates (lat, lon, elev, time)
                self.collision_tracking_data['coordinates']['original'][current_count:current_count+save_count] = coords[:save_count]
                # Save normalized coordinates (x_norm, y_norm, z_norm, time)
                self.collision_tracking_data['coordinates']['normalized'][current_count:current_count+save_count] = norm_coords[:save_count]
                # Update count
                self.collision_tracking_data['coordinates']['count'] += save_count

        # Encode
        if self.enable_collision_tracking:
            spatial_features, temporal_features = self.encoder(norm_coords, collision_tracking=self.collision_tracking_data)
        else:
            spatial_features, temporal_features = self.encoder(norm_coords)
        return torch.cat([spatial_features, temporal_features], dim=-1)

    def get_output_dim(self) -> int:
        """Return total output dimension."""
        return self.encoder.output_dim
    
    def export_collision_data(self, output_dir: str = "collision_analysis"):
        """
        Export complete collision tracking data for scientific analysis.
        
        Args:
            output_dir: Directory to save CSV and JSON files
            
        Returns:
            dict: Summary of exported data
        """
        if not self.enable_collision_tracking:
            raise RuntimeError("Collision tracking is not enabled. Initialize Earth4D with enable_collision_tracking=True")
        
        from pathlib import Path
        import pandas as pd
        import json
        
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        # Get number of tracked examples
        tracked_count = self.collision_tracking_data['coordinates']['count']
        if tracked_count == 0:
            raise RuntimeError("No collision data tracked yet. Run some forward passes first.")
        
        print(f"Exporting collision data for {tracked_count} tracked examples...")
        
        # Extract coordinates
        original_coords = self.collision_tracking_data['coordinates']['original'][:tracked_count].cpu().numpy()
        normalized_coords = self.collision_tracking_data['coordinates']['normalized'][:tracked_count].cpu().numpy()
        
        # Create base DataFrame with coordinates
        df_data = {
            'latitude': original_coords[:, 0],
            'longitude': original_coords[:, 1], 
            'elevation_m': original_coords[:, 2],
            'time_original': original_coords[:, 3],
            'x_normalized': normalized_coords[:, 0],
            'y_normalized': normalized_coords[:, 1],
            'z_normalized': normalized_coords[:, 2], 
            'time_normalized': normalized_coords[:, 3]
        }
        
        # Add grid indices for each grid space and level
        grid_metadata = {}
        
        for grid_name in ['xyz', 'xyt', 'yzt', 'xzt']:
            grid_data = self.collision_tracking_data[grid_name]
            indices = grid_data['collision_indices'][:tracked_count].cpu().numpy()
            flags = grid_data['collision_flags'][:tracked_count].cpu().numpy()
            
            num_levels = indices.shape[1]
            grid_metadata[grid_name] = {
                'num_levels': num_levels,
                'collision_rates_by_level': []
            }
            
            # Add columns for each level of this grid
            for level in range(num_levels):
                level_indices = indices[:, level, :]  # [tracked_count, 3]
                level_flags = flags[:, level]  # [tracked_count]
                
                # Add grid index columns
                for dim in range(3):
                    col_name = f"{grid_name}_level_{level:02d}_dim_{dim}"
                    df_data[col_name] = level_indices[:, dim]
                
                # Add collision flag column
                col_name = f"{grid_name}_level_{level:02d}_collision"
                df_data[col_name] = level_flags
                
                # Calculate collision rate for metadata
                collision_rate = float(level_flags.mean())
                grid_metadata[grid_name]['collision_rates_by_level'].append(collision_rate)
        
        # Create DataFrame and export CSV
        df = pd.DataFrame(df_data)
        csv_path = output_path / "earth4d_collision_data.csv"
        df.to_csv(csv_path, index=False)
        print(f"Exported grid indices to {csv_path}")
        
        # Create comprehensive metadata
        metadata = {
            'earth4d_config': {
                'spatial_levels': self.encoder.xyz_encoder.num_levels,
                'temporal_levels': self.encoder.xyt_encoder.num_levels,
                'spatial_log2_hashmap_size': getattr(self.encoder.xyz_encoder, 'log2_hashmap_size', 'unknown'),
                'temporal_log2_hashmap_size': getattr(self.encoder.xyt_encoder, 'log2_hashmap_size', 'unknown'),
                'max_tracked_examples': self.max_tracked_examples,
                'tracked_examples': tracked_count
            },
            'coordinate_ranges': {
                'latitude': [float(original_coords[:, 0].min()), float(original_coords[:, 0].max())],
                'longitude': [float(original_coords[:, 1].min()), float(original_coords[:, 1].max())],
                'elevation_m': [float(original_coords[:, 2].min()), float(original_coords[:, 2].max())],
                'time_original': [float(original_coords[:, 3].min()), float(original_coords[:, 3].max())]
            },
            'normalized_coordinate_ranges': {
                'x_normalized': [float(normalized_coords[:, 0].min()), float(normalized_coords[:, 0].max())],
                'y_normalized': [float(normalized_coords[:, 1].min()), float(normalized_coords[:, 1].max())],
                'z_normalized': [float(normalized_coords[:, 2].min()), float(normalized_coords[:, 2].max())],
                'time_normalized': [float(normalized_coords[:, 3].min()), float(normalized_coords[:, 3].max())]
            },
            'grid_analysis': grid_metadata,
            'csv_format': {
                'description': 'Each row represents one tracked coordinate with its grid indices across all levels',
                'coordinate_columns': ['latitude', 'longitude', 'elevation_m', 'time_original', 'x_normalized', 'y_normalized', 'z_normalized', 'time_normalized'],
                'grid_index_pattern': '{grid}_level_{level:02d}_dim_{dim}',
                'collision_flag_pattern': '{grid}_level_{level:02d}_collision',
                'grids': ['xyz', 'xyt', 'yzt', 'xzt']
            }
        }
        
        # Export metadata JSON
        json_path = output_path / "earth4d_collision_metadata.json"
        with open(json_path, 'w') as f:
            json.dump(metadata, f, indent=2)
        print(f"Exported metadata to {json_path}")
        
        # Create summary report
        summary = {
            'total_tracked_examples': tracked_count,
            'output_files': {
                'csv': str(csv_path),
                'json': str(json_path)
            },
            'collision_summary': {}
        }
        
        for grid_name in ['xyz', 'xyt', 'yzt', 'xzt']:
            rates = grid_metadata[grid_name]['collision_rates_by_level']
            summary['collision_summary'][grid_name] = {
                'overall_rate': float(np.mean(rates)),
                'fine_resolution_rate': float(np.mean(rates[-5:])),  # Last 5 levels
                'levels': len(rates)
            }
        
        print(f"\nCollision Summary:")
        for grid_name, stats in summary['collision_summary'].items():
            print(f"  {grid_name}: {stats['overall_rate']:.1%} overall, {stats['fine_resolution_rate']:.1%} fine resolution")
        
        return summary




# Example usage and testing
if __name__ == "__main__":
    print("Earth4D: Production-Ready Planetary Encoder")
    print("=" * 60)
    
    # Example 1: Production configuration (as used for AlphaEarth)
    print("\n1. Production Earth4D Configuration:")
    encoder = Earth4D(
        spatial_levels=24,
        temporal_levels=19,
        spatial_log2_hashmap_size=23,
        temporal_log2_hashmap_size=18,
        verbose=False
    )
    
    # Example coordinates: [lat, lon, elev_m, time_norm]
    coords = torch.tensor([
        [37.7749, -122.4194, 50.0, 0.5],   # San Francisco
        [40.7128, -74.0060, 100.0, 0.7],    # New York
        [-33.8688, 151.2093, 20.0, 0.3],   # Sydney
    ])
    
    features = encoder(coords)
    print(f"   Input shape: {coords.shape}")
    print(f"   Output features: {features.shape}")
    print(f"   Output dimension: {encoder.get_output_dim()}")
    
    # Example 2: Training setup
    print("\n2. Training Configuration Example:")
    
    class DeepEarthModel(torch.nn.Module):
        def __init__(self, target_dim=64):
            super().__init__()
            self.earth4d = Earth4D(
                spatial_levels=24,
                temporal_levels=19,
                spatial_log2_hashmap_size=23,
                temporal_log2_hashmap_size=18,
                verbose=False
            )
            encoder_dim = self.earth4d.get_output_dim()
            
            # Example MLP decoder
            self.decoder = torch.nn.Sequential(
                torch.nn.LayerNorm(encoder_dim),
                torch.nn.Linear(encoder_dim, 256),
                torch.nn.ReLU(),
                torch.nn.Dropout(0.1),
                torch.nn.Linear(256, target_dim),
                torch.nn.Tanh()
            )
        
        def forward(self, coords):
            features = self.earth4d(coords)
            return self.decoder(features)
    
    model = DeepEarthModel(target_dim=64)
    predictions = model(coords)
    print(f"   Model predictions shape: {predictions.shape}")
    
    # Calculate model size
    total_params = sum(p.numel() for p in model.parameters())
    earth4d_params = sum(p.numel() for p in model.earth4d.parameters())
    print(f"   Earth4D parameters: {earth4d_params:,}")
    print(f"   Total model parameters: {total_params:,}")
    print(f"   Model size (MB): {total_params * 4 / 1024 / 1024:.2f}")
    
    # Example 3: Different scale configurations
    print("\n3. Scale Configuration Examples:")
    configs = [
        ("Regional", 16, 19, "~10km resolution, 100MB"),
        ("Continental", 24, 22, "~1km resolution, 1GB (RECOMMENDED)"),
        ("Country", 32, 24, "~100m resolution, 4GB"),
    ]
    
    for name, levels, log2_size, desc in configs:
        print(f"   {name}: L={levels}, log2={log2_size} - {desc}")
    
    print("\n" + "=" * 60)
    print("Earth4D ready for planetary-scale deep learning!")
    print("Validated: 3.61% MAPE on AlphaEarth embeddings (3.2M samples)")
